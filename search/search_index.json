{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"Information of PGTEC <ul> <li> <p> Getting started</p> <p>Start by learning the basics of PGTEC.</p> <p> Learn more</p> </li> <li> <p> Data Sources</p> <p>Information of data sources for climate emergency management.   </p> <p> Learn more</p> </li> <li> <p> Data Flow</p> <p>The guide of a complete environment for the project.</p> <p> Learn more</p> </li> </ul>"},{"location":"welcome/","title":"Welcome","text":"<p>This site serves as a comprehensive documentation hub for the PGTEC project.  </p>"},{"location":"welcome/#about-pgtec","title":"About PGTEC","text":"<p>Following the devastating consequences of the DANA floods of 2024 in the province of Valencia, PGTEC aims to develop a platform for climate emergency prevention and management, providing advanced tools for the collection, analysis, and modeling of environmental and climate data.  </p> <p>This solution is integrated into interoperable data spaces, enabling public administrations, emergency management agencies, and companies in the climate sector to access real-time information for informed decision-making.</p>"},{"location":"welcome/#platform","title":"Platform","text":"<p>The platform will contribute to the digitalization of the climate resilience and emergency management sector, fostering the creation of data-driven products and services aligned with the principles of the European Data Strategy and the Recovery, Transformation and Resilience Plan.</p>"},{"location":"welcome/#beneficiary-sectors","title":"Beneficiary sectors","text":"<ul> <li>Emergency management and civil protection</li> <li>Environment and climate change  </li> <li>Public administration and smart cities </li> <li>Mobility and logistics</li> </ul> <p>Next steps</p> <p>Click on Getting started in the bottom navigation bar to advance to the next section.</p> <p>You can use the buttons in the bottom navigation bar to navigate between the previous and next pages or jump to a section with the side navigation bars.</p>"},{"location":"data_sources/","title":"Information","text":"<p>This section will detail the different data sources available to feed the prediction models and algorithms that will enable us to anticipate extreme weather events, thereby contributing to a more effective response to meteorological emergencies. Their usefulness, quality and availability will be evaluated.</p>"},{"location":"data_sources/#data-sources","title":"Data Sources","text":"<ul> <li> <p> Conferencia Hidrogr\u00e1fica del J\u00facar \u2013 SAIH</p> <p>Public body responsible for water management in the J\u00facar River Basin District.</p> <p> Learn more</p> </li> <li> <p> Sistema de Informaci\u00f3n Agroclim\u00e1tica para el Regad\u00edo (SiAR)</p> <p>Network of over 520 weather stations that captures, records, and disseminates agroclimatic data necessary to determine the water demand of irrigated farms.</p> <p> Learn more</p> </li> <li> <p> Agencia Estatal de Meteorolog\u00eda (AEMET)</p> <p>Official Spanish government agency responsible for observing, forecasting and studying meteorological phenomena.  </p> <p> Learn more</p> </li> <li> <p> AEMET (ROCIO)</p> <p>AEMET Observational Grid with Optimal Interpolation. </p> <p> Learn more</p> </li> <li> <p> AEMET (Spain02)</p> <p>Institutional collaboration between AEMET and the Santander Meteorology Group (SMG) at the University of Cantabria-CSIC.  </p> <p> Learn more</p> </li> <li> <p> Copernicus</p> <p>Project coordinated and managed by the European Commission.</p> <p> Learn more</p> </li> <li> <p> MSWEP</p> <p>Multi-Source Weighted-Ensemble Precipitation (MSWEP) is a high-resolution global precipitation dataset.  </p> <p> Learn more</p> </li> <li> <p> CEDEX</p> <p>It is the centre for studies and experimentation in public works.</p> <p> Learn more</p> </li> <li> <p> AVSRE</p> <p>The Valencian Agency for Security and Emergency Response (AVSRE) manages civil protection, emergency management, firefighting and public safety in the Valencian Community.</p> <p> Learn more</p> </li> </ul>"},{"location":"data_sources/metadata_datasources/aemet_datasource/","title":"Agencia Estatal de Meteorolog\u00eda (AEMET)","text":"<p>The State Meteorological Agency (AEMET) is the official Spanish government body responsible for observing, predicting and studying meteorological phenomena. As the main authority, AEMET provides reliable, consistent and standardised data, following the guidelines of the World Meteorological Organisation (WMO). </p> <p>Its AEMET OpenDataservice is the designated platform for disseminating this information, offering access to a wide range of meteorological and climatological products. The quality of its data is backed by rigorous validation processes and by the National Plan for the Prediction and Monitoring of Adverse Meteorological Phenomena (Meteoalerta), which establishes the risk thresholds for alerts. </p> <p>In the Valencian Community, there are approximately 40 meteorological stations that transmit data on a regular basis and are therefore used for live weather monitoring. </p> <p>It should be noted that, although real-time data is subject to automatic checks, it may contain occasional errors. Even so, the data collected by AEMET is considered to be of high quality due to its official nature. Consolidated climate data undergoes more exhaustive validation processes before its final publication. </p>"},{"location":"data_sources/metadata_datasources/aemet_datasource/#api","title":"API","text":"<p>The AEMET API is based on REST architecture and returns data mainly in JSON format, using international standards such as CAP (Common Alerting Protocol) for warnings and GeoJSON to represent affected areas.</p> <p>Data is available on:</p> <ul> <li>Meteorological observations</li> <li>Weather forecasts</li> <li>Radar and lightning</li> <li>Alerts</li> </ul> <p>With regard to historical data, there is no fixed start year for the data in the \u2018climatological values\u2019 section of the API. For daily, monthly and annual climatology and extreme values, the start date of the records depends on each individual weather station. For normal climatology, it returns average values calculated over the period from 1991 to 2020. </p> <p>The API is public, but registration is required. An API Key must be requested on the official AEMET OpenData. It is valid for three months and is linked to an email address. </p>"},{"location":"data_sources/metadata_datasources/aemet_rocio_datasource/","title":"AEMET (ROCIO)","text":"<p>The abbreviation ROCIO stands for Rejilla Observacional Con Interpolaci\u00f3n \u00d3ptima (Optimal Interpolation Observation Grid). AEMET has two types of grids to cover all island areas. The first high-resolution grid, approximately 5 km, covering mainland Spain and the Balearic Islands is called ROCIO_IBEB, and the second 2.5 km grid covering the Canary Islands is ROCIO_CAN. In both, the daily data on accumulated precipitation in 24 hours, maximum temperature and minimum temperature from a large number of stations of the State Meteorological Agency have been interpolated.   </p> <p>Therefore, for each grid there are two types of data sets available:  </p> <ul> <li> <p>Precipitation. </p> </li> <li> <p>Maximum and minimum temperatures. </p> </li> </ul> <p>With regard to the ROCIO_IBEB grid, the version 2 precipitation dataset has been generated using all the stations available in the AEMET National Climate Data Bank, i.e. 3,236 rainfall stations. This grid covers the period from 1951 to 2022 and is updated periodically.  </p> <p>The extreme temperature (maximum and minimum) datasets, version 1, have been generated using all the stations available in AEMET's National Climate Data Bank, 1,800 thermometric stations. These grids begin in 1951 and are updated until December 2022. Unlike the precipitation grid, they use climatology based on historical analyses of the HIRLAMnumerical prediction model operated by AEMET as initial information, or first estimate, which is corrected by observations.  </p> <p>With regard to the ROCIO_CAN grid, the precipitation and temperature datasets have been compiled in the same way as those for ROCIO_IBEB, but with projections using regular coordinates (latitude and longitude) thanks to the use of the HARMONIE model. In addition, the data cover the period from 1990 to 2022 but are updated periodically.  </p>"},{"location":"data_sources/metadata_datasources/aemet_rocio_datasource/#api","title":"API","text":"<p>The ROCIO grid data is available on the AEMET website and also from the THREDDS server at the University of Cantabria, displayed using the OpeNDAP protocol. This protocol allows access to variables such as precipitation and temperatures (maximum and minimum) on a 20 km grid, covering mainland Spain and the Balearic Islands. The dataset includes historical series since 1950 and is not updated in real time, as it consists of interpolated observational data. Therefore, there is no real-time data from the ROCIO grid. As a result, update times are unknown. </p>"},{"location":"data_sources/metadata_datasources/aemet_spain_datasource/","title":"AEMET (Spain02)","text":"<p>The Spain02 dataset is the result of institutional collaboration between the State Meteorological Agency (AEMET) and the Santander Meteorology Group (SMG) at the University of Cantabria-CSIC.  </p> <p>The dataset consists of a 20 km resolution grid covering mainland Spain and the Balearic Islands, generated using interpolation techniques based on daily observations at meteorological stations. The aim is to provide a homogeneous and continuous basis of climate information, suitable for regional analyses and climate change impact studies. </p> <p>Similar to the ROCIO grid, Spain02 includes precipitation and maximum and minimum temperature series, offering a homogeneous and continuous product over time, suitable for regional analyses, hydrological studies, climate change impact assessments and climate modelling. The availability of multiple interpolation versions and resolutions allows the data to be adapted to different scales of analysis and modelling methodologies, ensuring the robustness of the scientific studies that use them. </p>"},{"location":"data_sources/metadata_datasources/aemet_spain_datasource/#api","title":"API","text":"<p>The only way to access the SPAIN02 grid data is through the THREDDS data centre, which stores a replica of the data files. This data centre is developed and maintained by the University of Cantabria. This server allows you to browse the catalogue of available datasets and, using the OPeNDAP (Open-source Project for a Network Data Access Protocol) protocol, remotely query and extract only the necessary variables or subsets, without having to download the entire files. </p> <p>Update times are unknown. The data files only cover up to the year 2022, so there is no real-time data available. With regard to historical data, the data files contain data from 1951 onwards, so there are large volumes of historical data available. </p>"},{"location":"data_sources/metadata_datasources/avsre_datasource/","title":"AVSRE","text":"<p>The Valencian Agency for Security and Emergency Response (AVSRE) is the body of the Valencian Regional Government responsible for directing and managing civil protection, emergency management, firefighting and public safety in the Valencian Community. Its main function is to coordinate the various emergency services and ensure a rapid and effective response to any type of incident, including those of climatic origin. </p> <p>As a coordinating body, the AVSRE centralises a large amount of critical information for emergency management. This information comes from the following sources:</p> <ul> <li> <p>Calls to the 112 emergency telephone number: records of incidents reported by the public.</p> </li> <li> <p>First responders: police, fire brigade, health services, etc. </p> </li> <li> <p>Meteorological agencies: data and alerts from the State Meteorological Agency (AEMET) and the Valencian Cartographic Institute (ICV). </p> </li> <li> <p>Hydrographic confederations: information on the state of rivers and reservoirs. </p> </li> <li> <p>Firefighting consortia and civil protection units. </p> </li> </ul> <p>The AVSRE processes this information to generate alerts, coordinate the mobilisation of resources and provide up-to-date information to the public and the authorities.  </p> <p>The quality of the data managed by the AVSRE is considered high in terms of reliability and official status, as it is the body that centralises and verifies the information from all the agencies involved in an em</p>"},{"location":"data_sources/metadata_datasources/avsre_datasource/#api","title":"API","text":"<p>The AVSRE publishes institutional information, plans and notices, but the operational data needed for flood management usually comes from various connected providers (AEMET, Hydrographic Confederations, local councils, local sensor networks). </p> <p>The Regional Government maintains an open data catalogue (GVA Oberta / data portal) where data sets and REST APIs are published for many regional and municipal services; the AVSRE consumes and coordinates these flows in its operation.</p> <ul> <li>Open data portal 'Dades Obertes GVA'</li> <li>Real-time information (Portal 112cv.gva.es and GVA Oberta)</li> </ul>"},{"location":"data_sources/metadata_datasources/cedex_datasource/","title":"CEDEX","text":"<p>CEDEX is the centre for public works studies and experimentation. It is a cutting-edge public body in the field of public works, mobility, inland and marine waters, the environment and climate change. It is attached to the Ministry of Transport and Sustainable Mobility, which also reports to the Ministry for Ecological Transition and Demographic Challenge.  </p> <p>CEDEX is divided into eight specialised technical units called Centres and Laboratories. From each centre, CEDEX provides high-level technical assistance, carries out applied research and technological development, and transfers knowledge through courses, conferences and seminars. Of the eight centres, the Centre for Hydrographic Studies stands out, providing the climate data necessary for this project. </p> <p>Its functions include the evaluation and certification of materials and techniques, the development of standards and regulations, and the promotion of R&amp;D&amp;I projects in line with national and European plans. In addition, it provides specialised technical assistance to administrations and private entities, collaborates in the conservation of infrastructure heritage, and promotes knowledge transfer through publications, courses and technical meetings. It also promotes national and international cooperation in the scientific-technical field and, in certain cases, acts as an arbitrator in disputes related to its area of competence. </p>"},{"location":"data_sources/metadata_datasources/cedex_datasource/#api","title":"API","text":"<p>CEDEX has a large amount of data available on its website. As such, it does not have an API for accessing the data. The data is fully accessible from the website itself.  </p> <p>Among the available data, CEDEX presents eight different databases, each covering a different area of those described above. The databases are as follows: </p> <ul> <li> <p>Environmental Restoration Portal </p> </li> <li> <p>Capacity Yearbook </p> </li> <li> <p>Noise Mapping System </p> </li> <li> <p>Coast and Sea Information System (INFOMAR) </p> </li> <li> <p>Spanish Precipitation Isotope Monitoring Network (REVIP) </p> </li> <li> <p>Spanish Water Information System (Hispagua) </p> </li> <li> <p>Catalogue of waste materials that can be used in construction </p> </li> </ul> <p>The database of interest for the project is the Flow Measurement Yearbook. This database is an official publication that compiles daily, monthly and annual data on flow rates measured at river and reservoir gauging stations. </p> <p>It includes hydrological records such as: </p> <ul> <li> <p>Average daily, monthly and annual flow rates. </p> </li> <li> <p>Precipitation and inflows in the basins.</p> </li> <li> <p>Information on the measuring stations (location, technical characteristics, etc.).</p> </li> <li> <p>Evapotranspiration data such as temperature and precipitation. </p> </li> </ul> <p>The data files are divided by each basin organisation. Among them is the J\u00facar Hydrographic Conference (CHJ), which has all the data on the reservoirs and the J\u00facar River, which is the basin of interest for the project. </p> <p>The update times are not defined on the website. The time range covered by the data is from the last century to a few years ago. Depending on the dataset downloaded, the time span is different. For example, for the CHJ data, specifically the daily data files on reservoirs, canals, rivers and evaporation, the time span is different. </p>"},{"location":"data_sources/metadata_datasources/copernicus_datasource/","title":"Copernicus","text":"<p>The Copernicus programme is a project coordinated and managed by the European Commission, which aims to achieve a comprehensive, continuous and autonomous high-quality Earth observation capability, the results of which are freely accessible to the scientific community, authorities and individuals.  </p> <p>The overall objective is to provide accurate, reliable and continuous information in order to, among other things, improve environmental management and conservation, understand and mitigate the effects of climate change, and ensure civil security. </p> <p>It aims to bring together different sources of information from environmental satellites and ground-based stations to provide a global view of the Earth's \u2018state of health\u2019. </p> <p>To this end, Copernicus has two sites where the different data it collects can be accessed:</p> <ul> <li> <p>Climate Data Store (CDS): A tool for accessing more than 140 data sets with information on the state of our climate around the world over the last 100 years. </p> </li> <li> <p>Atmosphere Data Store (ADS): A tool for accessing more than 100 data sets with satellite data from around the world and over the last 100 years. </p> </li> </ul> <p>The data sets presented are as follows:</p> <ul> <li> <p>ERA5-Land hourly data from 1950 to the present. </p> </li> <li> <p>RA5 hourly data from 1940 to the present. </p> </li> </ul>"},{"location":"data_sources/metadata_datasources/copernicus_datasource/#api","title":"API","text":"<p>The CDS, developed within the framework of the European Commission's Copernicus programme, makes a wide range of climate and atmospheric data available to the public. To access this information, the CDS API, called cdsapi, is mainly used, which is designed for use in Python. </p> <p>The API usage flow is simple and combines both the web interface and script automation: </p> <ul> <li> <p>Data selection on the website: From the Climate Data Store web portal, users can browse more than 140 available datasets, as well as more than 100 offered by the Atmosphere Data Store. Each dataset has filters to specify variables, time intervals, spatial resolution, and output format. </p> </li> <li> <p>Automatic script generation: Once the desired parameters have been selected, the platform automatically generates a Python script that uses the cdsapi library. This script can be run locally to download data, facilitating reproducibility and automation of the process. </p> </li> <li> <p>Download via API: The cdsapi library manages the connection to the CDS servers, authenticates the user's request, and downloads the selected files in the specified format (e.g., NetCDF or GRIB). </p> </li> </ul> <p>The API has a large amount of data available. For example, for the ERA5 hourly data set from 1940 to the present available from the Climate Data Store, we can download a large amount of data: temperature at different levels and soil types, wind, radiation, heat, clouds, lakes, water evaporation, precipitation and rain, snow, soil, vertical integrals, vegetation, and waves. </p> <p>Regarding real-time data, it should be noted that for the data sets analysed, the most recent data is from 6 days prior to the current day. The update time is daily, so each day that passes, data from day t-6 is added, where t is the current day.  </p> <p>With regard to historical data, ERA 5 and ERA5-Land have records dating back to 1940, providing data from almost 85 years ago. Figure 12 shows the years of data available for the ERA5 data set. </p>"},{"location":"data_sources/metadata_datasources/mswep_datasource/","title":"MSWEP","text":"<p>Multi-Source Weighted-Ensemble Precipitation (MSWEP) is a high-resolution global precipitation dataset. It does not include variables such as temperature, humidity, etc. Its main feature is that it combines or merges different types of data sources to obtain the most accurate and reliable rainfall estimate possible. The amount of precipitation is expressed in mm/3h. It is not an instantaneous precipitation rate. To obtain daily values, the eight 3-hour intervals that make up a day must be added together. To obtain average hourly rates, the 3-hour value would be divided by three.  </p> <p>The data is obtained through: </p> <ul> <li> <p>Data from land-based weather stations. </p> </li> <li> <p>Satellite estimates (including oceans and remote areas). </p> </li> <li> <p>Climate reanalysis data (atmospheric models that reconstruct past climate). </p> </li> </ul> <p>By merging each source, MSWEP is able to correct for the weaknesses of each source individually.  </p>"},{"location":"data_sources/metadata_datasources/mswep_datasource/#api","title":"API","text":"<p>MSWEP does not offer an API to which requests are made in real time. Instead, access to data is managed through standard protocols and formats for handling large scientific data sets, mainly through files. </p> <p>As mentioned above, the only data it contains is precipitation. It is presented as the amount of rainfall over a 3-hour period, measured in millimetres (mm).  </p> <p>There are two versions of the data: </p> <ul> <li> <p>Near-Real-Time (NRT): updated with a delay of approximately 3 to 12 hours.  </p> </li> <li> <p>Research version: this is a corrected and more accurate version that is updated with a delay of several months. </p> </li> </ul> <p>One of its features is full access to the historical record. Data is available from 1979 to the present, allowing for the analysis of trends, past extreme events, and the training of models with a very solid database. </p> <p>Access to MSWEP data is public for research and educational purposes. To access it, please contact MSWEP:</p> <ul> <li> <p>If you are affiliated with a commercial entity and would like to try MSWEP, please fill out the application form.  </p> </li> <li> <p>If you do not have a commercial affiliation and intend to use the product for non-commercial purposes, please use the Apply here form  in the Data licence section. Once you have completed the form, you will receive a link to the shared Google Drive folder once your request has been approved. </p> </li> </ul>"},{"location":"data_sources/metadata_datasources/siah_datasource/","title":"Confederaci\u00f3n Hidrogr\u00e1fica del J\u00facar \u2013 SAIH","text":"<p>The J\u00facar Hydrographic Confederation (CHJ) is the public body responsible for water management in the J\u00facar River Basin District, which covers a large part of the Valencian Community and areas of Castilla La Mancha, Aragon and Catalu\u00f1a. Its mission is to ensure sustainable water use, prevent risks associated with droughts and floods, and protect river ecosystems. </p> <p></p> <p>The J\u00facar Automatic Hydrological Information System (SAIH) is a technological network managed by the CHJ that collects real-time hydrological, hydraulic and meteorological data from across the entire basin. It consists of automatic sensors, measuring stations and a control centre that processes the information. Through the SAIH J\u00facar, the CHJ offers a comprehensive information system that connects institutional management with real-time monitoring technology. </p> <p>The SAIH collects data from three types of stations: </p> <ul> <li> <p>Gauges: measure the flow rate in rivers, tributaries and watercourses. They provide essential data for forecasting floods, assessing droughts and determining the availability of water resources. </p> </li> <li> <p>Reservoirs: record the volume of water stored, total capacity and daily variations. Key information for resource management, flood control and agricultural and urban planning.</p> </li> <li> <p>Rain gauges: collect accumulated precipitation at different time intervals. This allows for analysis of rainfall distribution and anticipation of extreme events. </p> </li> </ul>"},{"location":"data_sources/metadata_datasources/siah_datasource/#api","title":"API","text":"<p>The CHJ does not have a public API, although it does have a public dashboard, allowing access to all information without any verification via SAIH.</p> <p>To access SAIH data via its private API, you must contact the CHJ and make the relevant request.</p> More information <p>To access SAIH data through its private API, you must contact the CHJ and make the relevant request.  After this, you will obtain a username and password with which we will generate an authorisation token  that will be used to authenticate future requests.  </p> <p>In addition, you must be able to access their private network, specifically port 8000, either through  the IP whitelist or via a VPN connection.  </p> <p>The API address is: https://api-saih.chj.es:8000.  </p> <p>A graphical interface for the API is also available through the open source swagger tool. It can be accessed at https://api-saih.chj.es:8000/docs.</p> <p>Through the API, we can access real-time data from different sensors, updated every five minutes, which for the purposes of the project are classified into three types: </p> <ul> <li> <p>Rain gauges: these record accumulated rainfall in 1h, 4h, 12h and 24h and their operational status. </p> </li> <li> <p>Gauges: measure instantaneous flow with reference thresholds (low, medium and high) along with the date of the last measurement.  </p> </li> <li> <p>Reservoirs: report the elevation (metres above sea level (m a.s.l.)), the stored volume (hm\u00b3) and the inflow and outflow rates (m\u00b3/s).  </p> </li> </ul> Reservoirs Gauges Rain gauges 25 180 78 <p>In addition to real-time data, the J\u00facar Hydrographic Confederation also has historical data, although this is not accessible via API as it is not stored in a unified database but distributed across different time series. However, it is possible to perform an initial dump of this information into the platform's database, which would allow for its integration and subsequent exploitation. </p>"},{"location":"data_sources/metadata_datasources/siar_datasource/","title":"Sistema de Informaci\u00f3n Agroclim\u00e1tica para el Regad\u00edo (SiAR)","text":"<p>The Agroclimatic Information System for Irrigation (SiAR) of the Ministry of Agriculture, Fisheries and Food is a network of more than 520 weather stations that captures, records and disseminates agroclimatic data necessary to determine the water demand of irrigated farms. </p> <p>The Sub-Directorate General for Irrigation, Natural Roads and Rural Infrastructure of the Ministry of Agriculture has been developing, maintaining and updating SiAR for more than 20 years. SiAR is currently the largest source of agroclimatic information provided by both the Ministry and the autonomous communities. </p> <p>The SiAR network places special emphasis on maintaining the high quality and accuracy of the data it provides. </p> <p>There are more than 360 stations managed by the Ministry and more than 160 managed by the autonomous communities. The SiAR network in the Valencian Community has 55 stations located in irrigated areas. </p>"},{"location":"data_sources/metadata_datasources/siar_datasource/#api","title":"API","text":"<p>SiAR allows access to all your data via REST API, provided that the maximum number of requests and the maximum amount of data queried per day and per minute are respected. Each user has different restrictions regarding the maximum number of requests. </p> More information <p>The technical manual for using the SIAR API specifies: </p> <p>\"Each web client is restricted in the number of requests it can make throughout a day and within a one-minute interval. Similarly, and for identical reasons, the number of agroclimatic data that can be consulted in a day and in a minute will also be limited\"  (Ministry of Agriculture, Fisheries and Food [MAPA], 2023, p. 12). </p> <p>To find out about the restrictions, each user can check their limitations via the following URL: https://servicio.mapama.gob.es/apisiar/API/v1/Info/Accesos?ClaveAPI={PUT_API_KEY}. When using the API key provided, the SIAR returns a response in JSON format indicating the limitations of API use to the user. The results are:</p> <ul> <li> <p>Maximum number of accesses per minute: 15</p> </li> <li> <p>Maximum number of accesses per day: 240</p> </li> <li> <p>Maximum number of records per minute: 100</p> </li> <li> <p>Maximum number of records per day: 10,000 </p> </li> </ul> <p>With regard to the amount of data available, SIAR allows data to be downloaded at the autonomous community, province and station level for the whole of Spain. For example, there are 41 weather stations in the province of Valencia. </p> <p>The SIAR has been storing data since 1999, so the time span is 25 years. This means that historical data is accessible. </p> <p>With regard to real-time data, attempts have been made to download the most recent data for several stations, and the most recent data returned by the API is from two hours ago.</p> <p>The data update times are not known exactly. The update time is estimated to be 30 minutes, given that the finest temporal granularity is every 30 minutes. </p> <p>Regarding temporal resolution, the technical manual explains the different granularities for accessing data according to the required time span (hourly, daily, weekly, monthly, etc.). </p>"},{"location":"getting_started/","title":"Getting started","text":"<p>Embarking on your journey with PGTEC is made simple through our comprehensive Getting Started guide. This section is designed to help users familiarize themselves with the essential aspects of the PGTEC project.</p> <p>Next steps</p> <p>Ready to get started? Just click \"Next\" on the bottom navigation bar to continue!</p>"},{"location":"getting_started/interoperability/","title":"Interoperability","text":"<p>Interoperability is a key aspect of CitCom.ai\u2019s approach to ensuring that data can be securely and effectively shared across different systems and organizations. </p>"},{"location":"getting_started/interoperability/#idsa-documentation","title":"IDSA Documentation","text":"<ul> <li> <p>Key Layers: The IDS documentation emphasizes four primary layers\u2014technical, semantic, organizational, and legal\u2014that collectively underpin effective interoperability.</p> </li> <li> <p>Intra Data Space Interoperability: Within a single Data Space, a unified governance framework ensures that all participants adhere to the same protocols and models.</p> </li> <li> <p>Cross-Data Space Interoperability: When operating across multiple Data Spaces, additional coordination is required to bridge varying protocols and legal frameworks.</p> </li> </ul> <p>For a comprehensive explanation and additional context, please refer to the original IDS documentation on Interoperability in Data Spaces.</p>"},{"location":"getting_started/interoperability/#mims","title":"MIMs","text":"<p>MIMs stands for \"Minimal Interoperability Mechanisms\". These guidelines and standards were developed by the Open &amp; Agile Smart Cities (OASC) initiative to promote interoperability among different city systems and technologies, such as traffic management systems, waste management systems, and energy distribution systems. CitCom.ai project embraces minimal interoperability mechanisms (MIMs) as part of its approach. </p>"},{"location":"getting_started/interoperability/#interoperability-levels","title":"Interoperability levels","text":"<p>Interoperability in data spaces defines how diverse systems can seamlessly exchange, interpret, and use data. Interoperability can be conceptualized as a maturity model with three levels:</p>"},{"location":"getting_started/interoperability/#level-0-custom-integration","title":"Level 0 - Custom Integration","text":"<p>At Level 0, no standard exists for data exchange. Each system is integrated via wholly customized solutions. This results in interfaces that are highly specific to each data platform. Although functional, such integration is often brittle and difficult to scale because it lacks a common vocabulary or consistent protocols. The absence of shared standards limits the potential for cross-organizational data reuse.</p>"},{"location":"getting_started/interoperability/#level-1-pivotal-interoperability-points","title":"Level 1 - Pivotal Interoperability Points","text":"<p>At Level 1, the focus shifts to identifying and adopting pivotal interoperability points among different data platforms. Key mechanisms such as MIM1 NGSI-LD and MIM2 Smart Data Models serve as the foundational standards at this stage.</p> <ul> <li> <p>MIM1 NGSI-LD provides a standardized API for context information management, enabling different systems to share and retrieve structured data consistently.</p> </li> <li> <p>MIM2 Smart Data Models standardize how entities and their attributes are defined, ensuring that data from disparate sources uses a common language.</p> </li> </ul> <p>This level establishes core interoperability through shared data models and context management, even though individual systems may retain internal heterogeneity. </p>"},{"location":"getting_started/interoperability/#level-2-common-interface-with-integrated-security","title":"Level 2 - Common Interface with Integrated Security","text":"<p>At Level 2, interoperability is further enhanced by defining a standard interface typically through deploying a data space connector. This connector not only leverages the standards from Level 1 but also integrates a comprehensive security layer that includes:</p> <ul> <li> <p>Trust Frameworks: Mechanisms to establish and maintain trust among participants.</p> </li> <li> <p>Identity Management: Standardized approaches to manage and verify participant identities.</p> </li> <li> <p>Authorization and Trust Services: Policies and registries that enforce data usage rules and access control.</p> </li> </ul> <p>This unified interface simplifies plug-and-play integration and ensures that all data transactions are secure, standardized, and governed under a common framework</p>"},{"location":"getting_started/data_spaces/data_spaces/","title":"Data Spaces","text":""},{"location":"getting_started/data_spaces/data_spaces/#overview","title":"Overview","text":"<p>Data spaces (DS) refer to structured and managed environments where data from various sources is securely stored, shared, and utilized for AI and robotics applications within smart and sustainable cities. These data spaces are the project's core technology, enabling participants to access and leverage high-quality data for testing, experimentation, and validation of AI technologies.</p> <p>Data spaces support interoperability, ensuring that data from different sources can be combined and used while complying with regulations such as the GDPR and other EU directives. They provide the necessary infrastructure for managing data in a way that supports ethical considerations, cybersecurity, and the broader goals of creating a more digital and sustainable urban environment.</p> <p></p> More information <ul> <li>Data Space Support Center (DSSC): <ul> <li>Data Space Definition</li> </ul> </li> <li>Data Spaces for Smart Cities (DS4SCC):<ul> <li>Interactive portal for building data spaces in Smart Communities</li> </ul> </li> </ul>"},{"location":"getting_started/data_spaces/data_spaces/#minimum-viable-data-space","title":"Minimum Viable Data Space","text":"<p>A Minimum Viable Data Space (MVDS) is a basic configuration of a data space that includes only the essential components required (Trust Framework and Connector) to ensure interoperability and enable the secure and sovereign exchange of information between organisations. Its minimal approach aims to reduce initial complexity, support technological adoption, and provide a way to test the ecosystem\u2019s functionality before scaling to more comprehensive solutions.</p> <ul> <li> <p>Trust Anchor (TA): Responsible for managing trust in the data space. It is the manager of the identities of the different elements of the data space and of managing the trust in them. At least one TA shall exist in the data space, managed by the organization in charge of the data space. </p> </li> <li> <p>Data Space Connector (DSC): Responsible for managing the communication between the different elements of the data space. It oversees managing authentication, authorization and data access control. There must be at least two DSCs, one per organization, to be able to affirm that a data space exists.</p> </li> </ul> <p>This type of data space serves as a testing environment that facilitates the validation of data exchange models and a gradual migration from existing systems. Thanks to its streamlined structure, the MVDS is especially well-suited for demonstrations, pilots, or early implementation stages in collaborative settings where data sharing is expected to be trustworthy and controlled.</p>"},{"location":"pipeline/","title":"Data spaces","text":""},{"location":"pipeline/#overview","title":"Overview","text":"<p>The data space aims to centralise and standardise climate information from various sources so that it is available to organisations interested in early prevention of climate emergencies.</p> <p>The first phase in building the data space is data collection. To do this, it is not enough to simply collect information from different sources: it is necessary to ensure that the data is updated in real time, is in a standardised format and is easily accessible to different organisations and applications. </p> <p>To this end, a structured data flow is designed that covers several consecutive stages, from obtaining the data at source to its storage and distribution in the data space. This flow ensures that each piece of data collected goes through a process of capture, translation, standardisation, management and historical persistence, so that it can ultimately be integrated correctly and consistently into the data ecosystem. </p>"},{"location":"pipeline/#components-of-the-data-flow","title":"Components of the data flow","text":"<ul> <li> <p>Airflow: An orchestration tool that allows you to schedule and automate data collection tasks. It is responsible for periodically executing scripts that query APIs or download files from different sources. </p> </li> <li> <p>IoT Agent Ultralight: Acts as a translator for the data received. It converts information from sensors or APIs into a common, standardised format (in this case based on FIWARE Smart Data Models), ensuring consistency in variable names and units of measurement. </p> </li> <li> <p>Orion-LD (Context Broker): Core of the system. It manages, stores and distributes contextual information in JSON-LD format, allowing data to be queried in real time by different applications or services. </p> </li> <li> <p>QuantumLeap: Component specialised in historical storage. It receives data from the Context Broker and stores it in a temporary database, in this case CrateDB, thus facilitating its consultation and subsequent use for analysis, report generation or artificial intelligence model training. </p> </li> </ul>"},{"location":"pipeline/#stages-of-data-flow","title":"Stages of data flow","text":"<ul> <li> <p>Data collection: Climate data is collected periodically from different sources, mostly through REST APIs, although some comes from direct downloads from web pages. This process is automated with Apache Airflow, which, thanks to the use of DAGs (Directed Acyclic Graphs) in Python, allows dependencies to be defined, execution to be scheduled (e.g., hourly) and regular, reliable data updates to be ensured. </p> </li> <li> <p>Standardisation and translation: Each source uses different variables and formats, so it is necessary to unify names, units, and structures. This task is performed by the IoT Agent, which translates the information into common models defined by FIWARE's Smart Data Models. In this case, a climate model is used to ensure data interoperability for future applications. </p> </li> <li> <p>Contextual management and distribution: Standardised data is managed by the Orion-LD Context Broker, which stores and distributes it in JSON-LD format. This makes it easier for multiple applications or services to consume it consistently. </p> </li> <li> <p>Historical and analytical persistence: Finally, real-time data is stored in a historical database through QuantumLeap, which inserts it into CrateDB as time series. In this way, complete records are built that allow IIAMA to train machine learning and deep learning models, which are key to the prediction and early detection of adverse climate phenomena. </p> </li> </ul> <p></p>"},{"location":"pipeline/requirements/","title":"What do I need?","text":"<p>To correctly deploy and operate the data pipeline, the following components and requirements must be available:</p> <ul> <li> <p>Python: Required for implementing auxiliary scripts, data preprocessing tasks, and integration logic with external services.</p> </li> <li> <p>Docker Compose: Used to orchestrate and deploy the FIWARE stack.</p> </li> <li> <p>Airflow: Provides workflow orchestration, ensuring the automated and scheduled execution of data collection, transformation, and loading tasks.</p> </li> <li> <p>Access credentials: An API key or endpoint URL to connect to the external data sources supplying the raw information.</p> </li> <li> <p>Networking and FIWARE configuration: Proper network setup and FIWARE component configuration to allow seamless communication between all services in the stack.</p> </li> </ul>"},{"location":"pipeline/setup/","title":"Set up environment","text":"<p>This repository provides a complete environment for orchestration and management of IoT data, integrating a set of FIWARE-based components and workflow automation tools.</p>"},{"location":"pipeline/setup/#core-components","title":"Core Components","text":"<ul> <li>IoT Agent: Interface for receiving IoT device data and forwarding it to the appropriate FIWARE context entities.</li> <li>Orion-LD Context Broker: Core NGSI-LD\u2013based context management engine responsible for storing, updating, and distributing contextual information.</li> <li>QuantumLeap: Time-series database service that persists historical events and temporal data, supporting advanced analytics and AI model training.</li> <li>CrateDB: Serves as the historical storage backend within the FIWARE stack.</li> <li>MongoDB: Provides context data persistence for the Orion-LD Context Broker.</li> <li>Apache Airflow: Workflow orchestration through Directed Acyclic Graphs (DAGs), enabling automation and scheduling of data-processing pipelines.</li> </ul>"},{"location":"pipeline/setup/#repository-contents","title":"Repository Contents","text":"<ul> <li> <p>docker-compose.yml: Defines and configures all services and containers within the stack.</p> </li> <li> <p>dags/: Directory containing Airflow DAGs for automated workflows.</p> </li> <li> <p>Scripts:</p> <ul> <li>AEMET.py: Fetches meteorological data from the AEMET API.</li> <li>Copernicus.py: Retrieves Copernicus climate datasets for the province of Valencia using Python\u2019s cdsapi library.</li> <li>Flujo_Copernicus_orion.py: DAG that collects Copernicus data, registers it in the IoT Agent, and stores it in Orion-LD.</li> <li>Flujo_copernicus_orion_quantumleap.py: Enhanced DAG that extends the previous workflow by integrating QuantumLeap for historical data persistence in CrateDB. (Recommended DAG for production use.)</li> </ul> </li> </ul>"},{"location":"pipeline/setup/#setup-instructions","title":"Setup instructions","text":""},{"location":"pipeline/setup/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/PGTEC-VRAIN/Entorno-AirFlow_IotAgent_OrionLD_QuantumLeap.git\ncd Entorno-AirFlow_IotAgent_OrionLD_QuantumLeap\n</code></pre>"},{"location":"pipeline/setup/#start-the-containers","title":"Start the containers","text":"<pre><code>docker-compose up -d --build\n</code></pre> <ul> <li> <p>Use --build only if changes were made to the docker-compose.yml.</p> </li> <li> <p>The -d option runs services in the background (detached mode).</p> </li> </ul>"},{"location":"pipeline/setup/#verify-running-services","title":"Verify running services","text":"<pre><code>docker ps\n</code></pre>"},{"location":"pipeline/setup/#shut-down-the-environment","title":"Shut down the environment","text":"<ul> <li>From a new terminal: <pre><code>docker-compose down\n</code></pre></li> <li>Or interrupt the current process with CTRL + C.</li> </ul>"}]}